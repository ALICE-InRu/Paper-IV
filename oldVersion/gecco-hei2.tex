% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}
\input{shorthand}
\begin{document}

\conferenceinfo{GECCO'14,} {July 12-16, 2014, Vancouver, BC, Canada.}
\CopyrightYear{2014}
\crdata{TBA}
\clubpenalty=10000
\widowpenalty = 10000

\title{Evolutionary learning of weighted linear composite dispatching rules for scheduling}
%\subtitle{}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{2} 
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
%Helga Ingimundardottir\\ %\titlenote{PhD student}\\
%       \affaddr{University of Iceland}\\
%       \affaddr{Dunhaga 5, IS-107}\\
%       \affaddr{Reykjavik, Iceland}\\
%       \email{hei2@hi.is}
% 2nd. author
\alignauthor
%Thomas Philip Runarsson \\%\titlenote{Thesis advisor.}\\
 %      \affaddr{University of Iceland}\\
 %      \affaddr{Hjardarhagi 2-6, IS-107}\\
 %      \affaddr{Reykjavik, Iceland}\\
 %      \email{tpr@hi.is}
%\and  % use '\and' if you need 'another row' of author names
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
%email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
%(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
}
\date{29 January 2014}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}

A prevalent approach to solving job shop scheduling problems is to combine several relatively simple dispatching rules such that they may benefit each other for a given problem space. Generally, this is done on an ad-hoc basis, requiring expert knowledge from heuristics designer, or extensive exploration of suitable combinations of heuristics. The approach here, is to automate that selection, by translating dispatching rules into measurable features and optimising what their contribution should be via evolutionary search. The framework is straight forward and easy to implement and shows promising results. Various data distributions are investigated, for both job shop and flow shop problems, as is scalability for higher dimensions. 

Moreover, the study shows that the choice of objective function  for evolutionary search is worth investigating. Since the optimisation is based on minimising the expected mean of the fitness function over a large set of problem instances, which can vary within. Then normalising the objective function can stabilise the optimisation process away from local minima. 

\end{abstract}

% A category with the (minimum) three required fields, optional field follows...
% see: http://www.acm.org/about/class/ccs98-html
\category{G.1.6}{Numerical Analysis}{Optimization}[Integer programming]
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Algorithms, Experimentation}

\keywords{Job Shop Scheduling, Composite Dispatching Rules, Evolutionary Search} % NOT required for Proceedings

\section{Job shop scheduling}

The job-shop scheduling problem (JSP) deals with the allocation of tasks of competing resources where the goal is to optimise a single or multiple objectives, in particular minimising a schedule's maximum completion time, i.e. the makespan, denoted $C_{\max}$. Due to difficulty in solving this problem, heuristics are generally applied. Perhaps the simplest approach to generating good feasible solutions for JSP is by applying dispatching rules (DR),  e.g., choosing a task corresponding to longest or shortest operation time; most or least successors; or ranked positional weight, i.e., sum of operation times of its predecessors. Ties are broken in an arbitrary fashion or by another heuristic rule. Combining dispatching rules for JSP is promising, however, there is a large number of rules to choose from thus its combinations relies on expert knowledge or extensive trial-and-error process to choose a suitable DR \cite{Tay08}. Hence given the diversity within the JSP paradigm, there is no ``one-rule-fits-all'' for all problem instances (or shop constraints), however single priority dispatching rules (SDR) based on job processing attributes have proven to be effective~\cite{Haupt89}. 
The classical dispatching rules are continually used in research; a summary of over $100$ classical DR for JSP can be found in \cite{Panwalkar77}. 
However, careful combinations of such simple rules, i.e. composite dispatching rules (CDR), can perform significantly better \cite{Jayamohan04}. 
As a consequence a linear composite of dispatching rule for JSP was presented by in \cite{InRu11a}. There the goal was to learn a set of weights, $\vec{w}$ via logistic regression such that 
\begin{equation}\label{eq:jssp:linweights}
h(\vec{x}_j)=\inner{\vec{w}}{\vphi(\vec{x}_j)},
\end{equation}
yields the preference estimate for dispatching job $j$ that corresponds to post-decision state $\vec{x}_j$, where $\vphi(\vec{x}_j)$ denotes the feature mapping. The job dispatched is the following, 
\begin{equation}\label{eq:jstar}
j^* = \arg\max_j\left\{h(\vec{x}_j)\right\}. 
\end{equation}
%The features may correspond to a DR, for example if only the single feature $\phi_6(\vec{x}_j) $ is applied it would correspond to MWR heuristic, namely yielding $h(\vec{x}_j)>h(\vec{x}_i)$, $\forall i$ which are jobs with less work remaining than job $j$. 

 






A more popular approach in recent JSP literature is applying genetic algorithms (GAs)~\cite{Pinedo08}. However, in that case an extensive number of schedules need to be evaluated, and even for low dimensional JSP that can quickly become computationally infeasible.
GAs can be used directly on schedules~\cite{Cheng96,Cheng99,Tsai07,Qing-dao-er-ji12,Ak12}, however, then there are many concerns that need to be dealt with. To begin with there are nine encoding schemes for representing the schedules~\cite{Cheng96}, in addition, special care must be taken when applying cross-over and mutation operators in order for schedules to still remain feasible. Moreover in case of JSP, GAs are not adapt for fine-tuning around optima, luckily a subsequent local search can mediate the optimisation~\cite{Cheng99}.

Another approach is to apply GAs indirectly to JSP, via dispatching rules, i.e. dispatching rules based genetic algorithms (DRGA)~\cite{Vazquez-Rodriguez09,Dhingra10,Nguyen13} where a solution is no longer a \emph{proper} schedule but a \emph{representation} of a schedule via applying certain DRs consecutively. 
DRGA are a special case of genetic programming~\cite{Koza05} which is the most predominant approach in hyper-heuristics is a framework of creating \emph{new} heuristics from a set of  predefined heuristics via GA optimisation~\cite{Burke10}. 

There are two main viewpoints on how to approach scheduling problems,
\begin{inparaenum}[\itshape a\upshape)] 
\item local level by building schedules for one problem instance at a time;
and \item global level by building schedules for all problem instances at once.
\end{inparaenum}
For local level construction a simple construction heuristic is applied, the schedule's features are collected at each dispatch iteration, from which a learning model will inspect the feature set to discriminate which operations are preferred to others via ordinal regression. The focus is essentially on creating a meaningful preference set composed of features and their ranks, as the learning algorithm is only run once to find suitable operators for the value function. This is the approach taken in~\cite{InRu11a}. Expanding on that  work, this study will explore global level construction viewpoint, where there is no feature set collected beforehand since the learning model is optimised directly via evolutionary search. This involves numerous costly value function evaluations. In fact it involves an indirect method of evaluation whether one learning model is preferable to another, w.r.t. which one yields a better expected mean. 

\section{Outline}
In order to formulate the relationship between problem structure and heuristic efficiency one can utilise Rice's framework for algorithm selection ~\cite{Rice76}. The framework consists of four fundamental components, namely,
\begin{description}
  \item[Problem space or instance space] $\mathcal{P}$, \hfill\\
  set of problem instances; 
  \item[Feature space] $\mathcal{F}$, \hfill\\
  measurable properties of the instances in $\mathcal{P}$;
  \item[Algorithm space] $\mathcal{A}$, \hfill\\
  set of all algorithms under inspection;
  \item[Performance space] $\mathcal{Y}$, \hfill\\
  the outcome for $\mathcal{P}$ using an algorithm from $\mathcal{A}$.
\end{description}
For a given problem instance $\vec{x}\in\mathcal{P}$ with $k$ features $\vec{\phi}(\vec{x})=\{\phi_1(\vec{x}),...,\phi_k( \vec{x})\}\in\mathcal{F}$ and using algorithm $a\in\mathcal{A}$ the performance is $y=Y(a,\vec{\phi}(\vec{x}))\in\mathcal{Y}$, where $Y:\;\mathcal{A}\times\mathcal{F} \mapsto \mathcal{Y}$ is the mapping for algorithm and feature space onto the performance space. 
\cite{SmithMilesLion3,SmithMilesLion5,InRu12} formulate JSP in the following manner: 
\begin{inparaenum}[\itshape a\upshape)] 
\item problem space $\mathcal{P}$ is defined as the union of $N$ problem instances consisting of processing time and ordering matrices given in~\cref{sec:data}; 
\item feature space $\mathcal{F}$, which is outlined in~\cref{sec:feat}. Note, these are not the only possible set of features, however, they are built on the work by~\cite{InRu11a,SmithMilesLion3} and deemed successful in capturing the essence of a JSP data structure;
\item algorithm space $\mathcal{A}$ is simply the scheduling policies under consideration and discussed in~\cref{sec:expr};
\item performance space is based on the resulting $C_{\max}$. Different fitness measures are investigated in~\cref{sec:expr:measure};
and \item mapping $Y$ is the step-by-step scheduling process. 
\end{inparaenum}

In the context of Rice's framework, and returning to the aforementioned approaches to scheduling problems, then the objective is to maximise its expected performance, i.e.
\begin{enumerate}[\itshape a\upshape)] 
\item Local level 
\begin{equation}
\max_{\mathcal{P}'\subset\mathcal{P}}~\mathbb{E}\left[Y\left(a,\vphi(\vec{x})\right)\right]
\end{equation}
where $\vec{x}\in\mathcal{P}'$ and algorithm $a$ is obtained via ordinal regression based on the feature space $\mathcal{F}$, i.e. $\mathcal{F}|_{\mathcal{P}'}\mapsto\mathcal{A}$, such as the approach taken in~\cite{InRu11a}, and  will be used as a benchmark for the following,  
%In addition, for global level,
\item  Global level
\begin{equation}
\max_{a\in\mathcal{A}}~\mathbb{E}\left[Y\left(a,\vphi(\vec{x})\right)\right]
\end{equation}
where training data $\vec{x}\in\mathcal{P}$ is guided by its algorithm $a$, i.e. $\mathcal{A}\mapsto\mathcal{P}$. This will be the focus of this study.
\end{enumerate}
Note that the mappings $\vphi:\mathcal{P}\mapsto\mathcal{F}$ and $Y:\mathcal{A}\mapsto\mathcal{Y}$ are the same for both paradigms.

The paper concludes in~\cref{sec:disc} with discussion and conclusions.









\section{Problem space}\label{sec:data}
For this study synthetic JSP and its subclass, permutation flow shop problem (PFSP), data instances will be considered with the problem size $n\times m$, where $n$ and $m$ denotes  number of jobs and machines, respectively. 

There are two fundamental types of problem classes: non-structured versus structured. 
Firstly there are the ``conventional'' structured problem classes, where problem instances for are generated stochastically by fixing the number of jobs and machines and processing time are i.i.d. and sampled from a discrete uniform distribution from the interval $I=[u_1,u_2]$, i.e. $p\sim \mathcal{U}(u_1,u_2)$.
Two different processing times distributions are explored, namely 
$\mathcal{P}_{j.rnd}$ where $I=[1,99]$ and $\mathcal{P}_{j.rndn}$ where $I=[45,55]$, referred to as random and random-narrow, respectively.
The machine order is a random permutation of all of the machines in the job-shop. 

Analogous to $\mathcal{P}_{j.rnd}$ and $\mathcal{P}_{j.rndn}$ the problem classes $\mathcal{P}_{f.rnd}$ and $\mathcal{P}_{f.rndn}$, respectively, correspond to the structured PFSP problem classes, however with a homogeneous machine order permutation.  
Secondly, there is a structured problem classes of PFSP which is modelled after real-world flow-shop manufacturing, namely, job-correlated $\mathcal{P}_{f.jc}$, where job processing times are dependent on job index, however independent of machine index.
Problem instances for PFSP are generated using~\cite{Whitley} problem generator\footnote{Both code, written in \texttt{C++}, and problem instances used in their experiments can be found at: \url{http://www.cs.colostate.edu/sched/generator/}}. 

For each JSP and PFSP class $N_{\text{train}}$  and $N_{\text{test}}$ instances were generated for training and testing, respectively. Values for $N$ are given in~\cref{tbl:data:sim}. Note, that difficult problem instances are not filtered out beforehand, such as the approach in~\cite{Whitley}. 


\begin{table}\centering
\caption{Problem space distributions used in~\cref{sec:expr}. Note, problem instances are synthetic and each problem space is i.i.d. and `--' denotes not available.}\label{tbl:data:sim}
{\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|l|c|c|c|l|}\hline 
name&size ($n\times m$)& $N_{\text{train}}$&$N_{\text{test}}$  & note 
\\ \hline\hline
\multicolumn{5}{|c|}{Permutation flow shop problem (PFSP)} \\ \hline
%\multirow{6}{*}{\begin{sideways}PFSP\end{sideways}}
$\mathcal{P}_{f.rnd}^{6\times5}$ &$6\times5$& 500&--& random \\ 
$\mathcal{P}_{f.rndn}^{6\times5}$&$6\times5$& 500&--& random-narrow \\ 
$\mathcal{P}_{f.jc}^{6\times5}$  &$6\times5$& 500&--& job-correlated \\ 
$\mathcal{P}_{f.rnd}^{10\times10}$ &$10\times10$&--&500&random \\ 
$\mathcal{P}_{f.rndn}^{10\times10}$&$10\times10$&--&500& random-narrow \\ 
$\mathcal{P}_{f.jc}^{10\times10}$  &$10\times10$&--&500& job-correlated \\ 
\hline\hline 
\multicolumn{5}{|c|}{Job shop problem (JSP)} \\ \hline
%\multirow{4}{*}{\begin{sideways}JSP\end{sideways}}
$\mathcal{P}_{j.rnd}^{6\times5}$ & $6\times5$ & 500 & -- & random \\
$\mathcal{P}_{j.rndn}^{6\times5}$ & $6\times5$ & 500 & -- & random-narrow \\
$\mathcal{P}_{j.rnd}^{10\times10}$ &$10\times10$& -- & 500 & random \\
$\mathcal{P}_{j.rndn}^{10\times10}$ &$10\times10$& -- & 500 & random-narrow \\ 
\hline
\end{tabular}
}
\end{table}




\section{Feature space}\label{sec:feat}
When building a complete JSP schedule $\ell=n\cdot m$ dispatches must be made sequentially. 
A job is placed at the earliest available time slot for its next machine, whilst still fulfilling constraints that each machine can handle at most one job at each time, and jobs need to have finished their previous machines according to its machine order. 
Unfinished jobs are dispatched one at a time according to some heuristic. After each dispatch the schedule's current features are updated.
Features are used to grasp the essence of the current state of the schedule. Temporal scheduling features applied in this study, for each possible post-decision state, are given in~\cref{tbl:jssp:feat}. An example of a schedule being built is given in~\cref{fig:jssp:example}, where there are a total of five possible jobs that could be chosen to be dispatched next by some dispatching rule. These features would serve as the input for~\cref{eq:jssp:linweights}. 

It's noted that some of the features directly correspond to a SDR commonly used in practice, for example if the weights were zero, save for $w_6=1$, then~\eqref{eq:jstar} yields the job with the highest \phiwrmJob\ value, i.e. equivalent  to dispatching rule most work remaining (MWR).


\begin{table}  
  \caption{Feature space $\mathcal{F}$ for $\mathcal{P}$ given the resulting temporal schedule after dispatching an operation.  }
  \label{tbl:jssp:feat}
  \input{features-description-simple}
\end{table}

\begin{figure}[t!]\centering 
\epsfig{file=fig/jssp_example_nocolor, width=\columnwidth}
\caption[Gantt chart of a partial JSP schedule]{Gantt chart of a partial JSP schedule after 15 dispatches: Solid boxes represent previously dispatched jobs, and dashed boxes represent  the jobs
that could be scheduled next. Current $C_{\max}$ denoted as dotted line.}
\label{fig:jssp:example}
\end{figure}


\section{Experimental study}\label{sec:expr}
The optimum makespan is denoted 
$C_{\max}^{\text{opt}}$, and the makespan obtained from the heuristic model by $C_{\max}^{\text{model}}$. Since 
the optimal makespan varies between problem instances the performance measure is the following, 
\begin{equation}\label{eq:ratio}\rho :=\frac{C_{\max}^{\text{model}}-C_{\max}^{opt}}{C_{\max}^{\text{opt}}}\cdot 
100\%\end{equation}
which indicates the percentage relative deviation from optimality. 

Inspired by DRGA, the approach taken in this study is to optimise the weights $\vec{w}$ in~\cref{eq:jssp:linweights} directly, via evolutionary search such as covariance matrix adaptation evolution strategy (CMA-ES) \cite{Hansen01}, which has been proven to be a very efficient numerical optimisation technique. 

Using standard set-up of parameters of the CMA-ES optimisation, the runtime was limited to 288 hours on a cluster for each training set given in~\cref{sec:data}, and in every case the optimisation reached its maximum walltime.

\subsection{Performance measures}\label{sec:expr:measure}
Generally, evolutionary search only needs to minimise the expected fitness value, however the  approach in~\cite{InRu11a} was to use the known optimum to correctly label which operations' features were indeed optimal compared to other possible operations, then it would be of interest to inspect if there is any performance edge gained in incorporating optimal labelling in evolutionary search. Therefore, two objective functions will be considered, namely, 
\begin{equation}
ES_{C_{\max}} := \min \Exp[C_{\max}] \label{eq:cma:makespan}
\end{equation}
\begin{equation}
ES_{\rho} := \min \Exp[\rho] \label{eq:cma:rho}
\end{equation} 
Main statistics of the experimental run are given in~\cref{cma:funeval} and depicted in~\cref{fig:cma:fit} for both approaches. In addition, evolving decision variables, here weights $\vec{w}$ for~\cref{eq:jssp:linweights}, are depicted in~\cref{fig:cma:wei}. 

In order to compare the two objective functions, the best weights reported were used for~\cref{eq:jssp:linweights} on the corresponding training data. Its box-plot of percentage relative deviation from optimality, defined by~\cref{eq:ratio}, is depicted in~\cref{fig:cma:trainboxpl} and main statistics detailed in~\cref{tbl:results:train}. 

In the case of $\mathcal{P}_{f.rndn}$,~\cref{eq:cma:rho}  gave a considerably worse results, since the optimisation got trapped in a local minimum, as the erratic evolution of the weighs in~\cref{fig:cma:wei:cmax} suggest.
For other problem spaces,~\cref{eq:cma:makespan} gave slightly better results than~\cref{eq:cma:rho}, however, there was no statical difference between adopting either objective function. Therefore, minimisation of expectation of $\rho$, is preferred over simply using the unscaled resulting makespan. 

\begin{table}\centering
\caption{Final results for CMA-ES optimisation.}\label{cma:funeval}
\begin{tabular}{|l|rrr|rrr|}\hline
$\mathcal{P}$ & \#gen & \#eval & ES$_{C_{\max}}$ & \#gen & \#eval & ES$_\rho$ \\
\hline\hline
f.jc & 5984 & 65835 & 567.688  & 1625 & 17886 & 0.361 \\
f.rnd & 5088 & 55979 & 571.394 & 4546 & 50006 & 7.479 \\
f.rndn & 5557 & 61138 & 544.764 & 2701 & 29722 & 0.938 \\
j.rnd & 4707 & 51788 & 448.612 & 1944 & 21395 & 8.258 \\
j.rndn & 4802 & 52833 & 449.942 & 1974 & 21725 & 8.691 \\
\hline
\end{tabular}
\end{table}

\begin{figure}
\epsfig{file=fig/CMAboxplotEvoTrain,width=\columnwidth}
\caption{Box-plot of training data for percentage relative deviation from optimality, defined by~\cref{eq:ratio}, when implementing the final weights obtained from CMA-ES optimisation, using both objective functions from~\cref{eq:cma:makespan,eq:cma:rho}, left and right, respectively.}\label{fig:cma:trainboxpl}
\end{figure}

\subsection{Problem difficulty}\label{sec:expr:data}
The evolution of fitness per generation from the CMA-ES optimisation of~\cref{eq:cma:rho} is depicted in~\cref{fig:cma:fit}, and since all problem spaces reached their allotted computational time, without converging. In fact $\mathcal{P}_{f.rnd}$ and $\mathcal{P}_{j.rndn}$ needed restarting during the optimisation process. 
Furthermore, the  evolution of the decision variables, $\vec{w}$, are depicted in~\cref{fig:cma:wei}. As one can see, the relative contribution for each weight clearly differs between problem spaces. Note that in the case of $\mathcal{P}_{j.rndn}$ (cf.~\cref{fig:cma:wei:rho}), CMA-ES restarts around generation 1,000 and quickly converges back to its previous fitness, however lateral relation of weights has completely changed. Implying that there are many optimal combinations of weights to be used, which can be expected due  to the fact some features in~\cref{tbl:jssp:feat} are a linear combination of one others, e.g. $\phi_3=\phi_1+\phi_2$.

\begin{figure} % spans two columns
\epsfig{file=fig/CMAfitnessEvo, width=\columnwidth}
\caption{Fitness for optimising (w.r.t.~\cref{eq:cma:makespan,eq:cma:rho} above and below, receptively), per generation of the CMA-ES optimisation.}\label{fig:cma:fit}
\end{figure}

\begin{figure*} 
\subfloat[][minimise w.r.t.~\cref{eq:cma:makespan}]{\epsfig{file=fig/CMAweightsEvomin_Cmax, width=\columnwidth}\label{fig:cma:wei:cmax}}
~
\subfloat[][minimise w.r.t.~\cref{eq:cma:rho}]{\epsfig{file=fig/CMAweightsEvomin_Rho, width=\columnwidth}\label{fig:cma:wei:rho}}
\caption{Evolution of weights of features (given in~\cref{tbl:jssp:feat}) at each generation of the CMA-ES optimisation. Note, weights are normalised such that $\norm{\vec{w}}=1$.}\label{fig:cma:wei}
\end{figure*}


\subsection{Robustness and  scalability}\label{sec:expr:robust} 
As a benchmark, the linear ordinal regression model (PREF) from~\cite{InRu11a} was created.
Using the weights obtained from optimising~\cref{eq:cma:rho} and applying them on their  $6\times5$ training data, their main statistics of~\cref{eq:ratio} are reported in~\cref{tbl:results:train}, for all training sets described in~\cref{tbl:data:sim}. Moreover, the best SDR, from which the features in~\cref{tbl:jssp:feat} were inspired by, are also reported for comparison, i.e. most work remaining (MWR) for all JSP problem spaces, and least work remaining (LWR) for all PFSP problem spaces.

To explore the scalability of the learning methods, a similar comparison to~\cref{sec:expr:robust} is made for the applying the learning models on their corresponding $10\times10$ testing data, results are reported in~\cref{tbl:results:test}. Note that only resulting $C_{\max}$ is reported, as the optimum makespan is not known. 

\begin{table}[b!]\centering
\caption{Main statistics of percentage relative deviation from optimality, $\rho$, defined by~\cref{eq:ratio} for various models, using corresponding $6\times5$ training data.}
\label{tbl:results:train}
%jsp
\subfloat[][$\mathcal{P}_{ j.rnd }^{6\times5}$]{\label{tbl:train:j.rnd}
\begin{tabular}{lrrrrr} \hline
model&mean & med & sd & min & max \\   \hline
ES$_{C_{\max}}$& 8.54 & 10 &  6 &  0 & 26   \\ % CMA-ES min_Cmax j.rnd 6x5 train
ES$_\rho$& 8.26 & 10 &  6 &  0 & 26   \\ % CMA-ES min_rho j.rnd 6x5 train
PREF&   10.18 & 11 &  7 &  0 & 30  \\ %PREF j.rnd 6x5 train
MWR &  16.48 & 16 &  9 &  0 & 45   \\ %MWR j.rnd 6x5 train
\hline \end{tabular}}
\\
\subfloat[][$\mathcal{P}_{ j.rndn }^{6\times5}$]{\label{tbl:train:j.rndn}
\begin{tabular}{lrrrrr} \hline
model&mean & med & sd & min & max \\   \hline
ES$_{C_{\max}}$& 8.68 & 11 &  6 &  0 & 31   \\ % CMA-ES min_Cmax j.rndn 6x5 train
ES$_\rho$& 8.69 & 11 &  6 &  0 & 31   \\ % CMA-ES min_rho j.rndn 6x5 train
PREF&  10.00 & 11 &  6 &  0 & 31   \\ %PREF j.rndn 6x5 train
MWR &  14.02 & 13 &  8 &  0 & 37   \\ %MWR j.rndn 6x5 train
\hline \end{tabular}}
%flow shop
\\
\subfloat[][$\mathcal{P}_{ f.rnd }^{6\times5}$]{\label{tbl:train:f.rnd}
\begin{tabular}{lrrrrr} \hline
model&mean & med & sd & min & max \\   \hline
ES$_{C_{\max}}$& 7.44 &  7 &  5 &  0 & 23   \\ % CMA-ES min_Cmax f.rnd 6x5 train
ES$_\rho$& 7.48 &  7 &  5 &  0 & 34   \\ % CMA-ES min_rho f.rnd 6x5 train
PREF&   9.87 &  9 &  7 &  0 & 38  \\ %PREF f.rnd 6x5 train
LWR &  20.05 & 19 & 10 &  0 & 71   \\ %LWR f.rnd 6x5 train
\hline \end{tabular}}
\\
\subfloat[][$\mathcal{P}_{ f.rndn }^{6\times5}$]{\label{tbl:train:f.rndn}
\begin{tabular}{lrrrrr} \hline
model&mean & med & sd & min & max \\   \hline
ES$_{C_{\max}}$& 8.09 &  8 &  2 &  0 & 11   \\ % CMA-ES min_Cmax f.rndn 6x5 train
ES$_\rho$& 0.94 &  1 &  1 &  0 &  4   \\ % CMA-ES min_rho f.rndn 6x5 train
PREF&   2.38 &  2 &  1 &  0 &  7  \\ %PREF f.rndn 6x5 train
LWR &  2.25 &  2 &  1 &  0 &  7   \\ %LWR f.rndn 6x5 train
\hline \end{tabular}}
\\
\subfloat[][$\mathcal{P}_{ f.jc }^{6\times5}$]{\label{tbl:train:f.jc}
\begin{tabular}{lrrrrr} \hline
model&mean & med & sd & min & max \\   \hline
ES$_{C_{\max}}$& 0.33 &  0 &  0 &  0 &  2   \\ % CMA-ES min_Cmax f.jc 6x5 train
ES$_\rho$& 0.36 &  0 &  0 &  0 &  2   \\ % CMA-ES min_rho f.jc 6x5 train
PREF&   1.08 &  1 &  1 &  0 &  5  \\ %PREF f.jc 6x5 train
LWR &  1.13 &  1 &  1 &  0 &  6   \\ %LWR f.jc 6x5 train
\hline \end{tabular}}
\end{table}

\begin{table}[b!]\centering
\caption{Main statistics of $C_{\max}$ for various models, using corresponding $10\times 10$ test data.}
\label{tbl:results:test}
%jsp
\subfloat[][$\mathcal{P}_{ j.rnd }^{10\times10}$]{\label{tbl:test:j.rnd}
\begin{tabular}{lrrrrr}
  \hline
model&mean & med & sd & min & max \\ 
  \hline
ES$_{C_{\max}}$& 922.51 & 914 & 73 & 741 & 1173   \\ % CMA-ES min_Cmax j.rnd 10x10 test
ES$_\rho$& 931.37 & 931 & 71 & 735 & 1167   \\ % CMA-ES min_rho j.rnd 10x10 test
  PREF&   1011.38 & 1004 & 82 & 809 & 1281 \\   %PREF j.rnd 10x10 test
  MWR &  997.01 & 992 & 81 & 800 & 1273   \\ %MWR j.rnd 10x10 test
   \hline
\end{tabular}}
\\
\subfloat[][$\mathcal{P}_{ j.rndn }^{10\times10}$]{\label{tbl:test:j.rndn}
\begin{tabular}{lrrrrr}
  \hline
model& mean & med & sd & min & max \\ 
  \hline
ES$_{C_{\max}}$& 855.85 & 857 & 50 & 719 & 1010   \\ % CMA-ES min_Cmax j.rndn 10x10 test
ES$_\rho$& 855.91 & 856 & 51 & 719 & 1020   \\ % CMA-ES min_rho j.rndn 10x10 test
  PREF&   899.94 & 898 & 56 & 769 & 1130  \\ %PREF j.rndn 10x10 test
  MWR&  897.39 & 898 & 56 & 765 & 1088   \\ %MWR j.rndn 10x10 test
   \hline
\end{tabular}}
%flow shop
\\
\subfloat[][$\mathcal{P}_{ f.rnd }^{10\times10}$]{\label{tbl:test:f.rnd}
\begin{tabular}{lrrrrr} \hline
model&mean & med & sd & min & max \\   \hline
ES$_{C_{\max}}$& 1178.73 & 1176 & 80 & 976 & 1416   \\ % CMA-ES min_Cmax f.rnd 10x10 test
ES$_\rho$& 1181.91 & 1179 & 80 & 984 & 1404   \\ % CMA-ES min_rho f.rnd 10x10 test
PREF&  1215.20 & 1212 & 80 & 1006 & 1450  \\ %PREF f.rnd 10x10 test
LWR &  1284.41 & 1286 & 85 & 1042 & 1495   \\ %LWR f.rnd 10x10 test
\hline \end{tabular}}
\\
\subfloat[][$\mathcal{P}_{ f.rndn }^{10\times10}$]{\label{tbl:test:f.rndn}
\begin{tabular}{lrrrrr} \hline
model&mean & med & sd & min & max \\   \hline
ES$_{C_{\max}}$& 1065.48 & 1059 & 32 & 992 & 1222   \\ % CMA-ES min_Cmax f.rndn 10x10 test
ES$_\rho$& 980.11 & 980 &  8 & 957 & 1006   \\ % CMA-ES min_rho f.rndn 10x10 test
PREF&  987.49 & 988 &  9 & 958 & 1011  \\ %PREF f.rndn 10x10 test
LWR &  986.94 & 987 &  9 & 959 & 1010   \\ %LWR f.rndn 10x10 test
\hline \end{tabular}}
\\
\subfloat[][$\mathcal{P}_{ f.jc }^{10\times10}$]{\label{tbl:test:f.jc}
\begin{tabular}{lrrrrr} \hline
model&mean & med & sd & min & max \\   \hline
ES$_{C_{\max}}$& 1135.44 & 1134 & 286 & 582 & 1681   \\ % CMA-ES min_Cmax f.jc 10x10 test
ES$_\rho$& 1135.47 & 1134 & 286 & 582 & 1681   \\ % CMA-ES min_rho f.jc 10x10 test
PREF&   1136.02 & 1135 & 286 & 582 & 1685 \\  %PREF f.jc 10x10 test
LWR &  1136.49 & 1141 & 287 & 581 & 1690   \\ %LWR f.jc 10x10 test
\hline \end{tabular}}

\end{table}






\section{Discussion and conclusions}\label{sec:disc}
Data distributions considered in this study either varied 
w.r.t. the processing times distributions, continuing the preliminary experiments in ~\cite{InRu11a} , or 
w.r.t. the job ordering permutations, i.e. homogeneous $\sigma$ matrices in PFSP versus heterogeneous $\sigma$ matrices in JSP. 
From the results based on $6\times5$ training data, given  in~\cref{tbl:results:train}, it's obvious that CMA-ES optimisation substantially outperforms the previous PREF methods from~\cite{InRu11a}, for all problem spaces considered. Furthermore, the results hold when testing on $10\times10$, (cf.~\cref{tbl:results:test}), suggesting the method is indeed  scalable for higher dimensions. 

Moreover, the study showed that the choice of objective function  for evolutionary search is worth investigating. There was no statistical difference from minimising the fitness function directly and its normalisation w.r.t. true optimum (cf.~\cref{eq:cma:makespan,eq:cma:rho}), save for $\mathcal{P}_{f.rndn}$. Implying, even though ES doesn't rely on optimal solutions, there are some problem spaces where it can be of great benefit. This is due to the fact that the problem instances can vary greatly within the same problem space \cite{InRu12}, thus normalising the objective function would help the evolutionary search to deviate the from giving too much weight for problematic problem instances for the greater good.


%The weights for~\cref{eq:jssp:linweights} in~\cite{InRu11a} were found using supervised learning, where the training data was created from optimal solutions of randomly generated problem instances. As an alternative, this study showed  that minimising the mean makespan directly using a brute force search via CMA-ES actually results in a better CDRs. The nature of CMA-ES is to explore suboptimal routes until it converges to an optimal one. Implying that the previous approach of only looking into one optimal route may not produce a sufficiently rich training set. That is, the training set should incorporate a more complete knowledge on \emph{all} possible preferences, i.e. make also the distinction between suboptimal and sub-suboptimal features, etc.  This would require a Pareto ranking of preferences which can be used to make the distinction to which feature sets are equivalent, better or worse -- and to what degree, i.e. by giving a weight to the preference. This would result in a very large training set, which of course could be re-sampled in order to make it computationally feasible to learn.

The main drawback of using evolutionary search for learning optimal weights for~\cref{eq:jssp:linweights} is how computationally expensive it is to evaluate the mean expected fitness. Even for a low problem dimension, 6-job 5-machine JSP, each optimisation run reached their walltime of 288hrs, without converging. Now, $6\times5$ JSP requires 30 sequential dispatches, where at each time step there are up to $6$ jobs to choose from, i.e. its complexity is $\mathcal{O}(n^{n\cdot m})$, making it computationally infeasible to apply this framework for higher dimensions as is. 
However, evolutionary search only requires the rank of the candidates, and therefore it is appropriate to retain a sufficiently accurate surrogate for the value function during evolution in order to reduce the number of costly true value function evaluations, such as the approach in~\cite{InRu11b}. This could reduce the computational cost of the evolutionary search considerably, making it feasible to conduct the experiments from~\cref{sec:expr} for problems of higher dimensions, e.g. with these adjustments it is possible to train on $10\times10$ and test on for example $14\times14$ to verify whether scalability holds for even higher dimensions.  





%ACKNOWLEDGMENTS are optional
%\section{Acknowledgments}

% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{../references}  
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
%\appendix
%\balancecolumns
% That's all folks!
\end{document}